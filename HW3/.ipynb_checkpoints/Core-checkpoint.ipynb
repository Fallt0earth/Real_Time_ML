{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa35c075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "import torch\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "from torchvision import datasets\n",
    "data_path = \"./data/\"\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e2abd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32, 10000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "tensor_cifar10 = datasets.CIFAR10(data_path, train=True, download=False, transform=transforms.ToTensor())\n",
    "imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim=3)\n",
    "imgs.shape\n",
    "tensor_cifar10_val = datasets.CIFAR10(data_path, train=False, download=False, transform=transforms.ToTensor())\n",
    "imgs_val = torch.stack([img_t for img_t, _ in tensor_cifar10_val], dim=3)\n",
    "imgs_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1754447a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.2435, 0.2616))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms.Normalize((0.4914, 0.4822, 0.4465),  (0.2470, 0.2435, 0.2616))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81189c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "transformed_cifar10 = datasets.CIFAR10(data_path, train=True, download=False, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465),  (0.2470, 0.2435, 0.2616))]))\n",
    "img_t, _  = transformed_cifar10[99]\n",
    "plt.imshow(img_t.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9692384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.Normalize((0.4942, 0.4851, 0.4504),  (0.2467, 0.2429, 0.2616))\n",
    "val_transformed_cifar10 = datasets.CIFAR10(data_path, train=False, download=False, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465),  (0.2470, 0.2435, 0.2616))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8abb4a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=5):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c8a4a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0')\n",
    "train_loader = torch.utils.data.DataLoader(transformed_cifar10, batch_size=64, shuffle=True)\n",
    "\n",
    "model = CNN()\n",
    "model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5339d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def training(model, optimizer, loss_fn, n_epochs, device, train_loader):\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            print(imgs.shape)\n",
    "            batch_size = imgs.shape[0]\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn((outputs), labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "    end = time.time()\n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1efbc42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([16, 3, 32, 32])\n",
      "Epoch: 0, Loss: 1.674438\n",
      "11.919096946716309\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "training(model, optimizer, loss_function, n_epochs, device, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19d0a652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleLinear ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleLinear ptflops can affect your code!\n",
      "Computational complexity:       0.0 GMac\n",
      "Number of parameters:           76.04 k \n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "\n",
    "macs, params = get_model_complexity_info(model, ( 3, 32,32), as_strings=True, print_per_layer_stat=False, verbose=False)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f2b92375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.6964\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_transformed_cifar10, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size=imgs.shape[0]\n",
    "        outputs = model(imgs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "#         print(predicted)\n",
    "#         print(\"\\n\")\n",
    "#         print(labels)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted==labels).sum())\n",
    "    print(\"Accuracy \", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a9c535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1b\n",
    "import torch.nn.functional as F\n",
    "class CNN2(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=5):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, 16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, n_chans1, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv3(out)), 2)\n",
    "        out = out.view(-1, 4 * 4 * self.n_chans1)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3109c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0')\n",
    "train_loader = torch.utils.data.DataLoader(transformed_cifar10, batch_size=64, shuffle=True)\n",
    "\n",
    "model = CNN2()\n",
    "model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89e870d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def training(model, optimizer, loss_fn, n_epochs, device, train_loader):\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            batch_size = imgs.shape[0]\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn((outputs), labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "    end = time.time()\n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fcc8beeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.997500\n",
      "Epoch: 1, Loss: 1.247931\n",
      "Epoch: 2, Loss: 1.422059\n",
      "Epoch: 3, Loss: 1.039534\n",
      "Epoch: 4, Loss: 1.245430\n",
      "Epoch: 5, Loss: 1.028163\n",
      "Epoch: 6, Loss: 1.332770\n",
      "Epoch: 7, Loss: 1.004782\n",
      "Epoch: 8, Loss: 1.107149\n",
      "Epoch: 9, Loss: 0.682346\n",
      "Epoch: 10, Loss: 0.589408\n",
      "Epoch: 11, Loss: 0.924874\n",
      "Epoch: 12, Loss: 1.048821\n",
      "Epoch: 13, Loss: 0.720066\n",
      "Epoch: 14, Loss: 1.451478\n",
      "Epoch: 15, Loss: 0.611591\n",
      "Epoch: 16, Loss: 0.555423\n",
      "Epoch: 17, Loss: 0.629543\n",
      "Epoch: 18, Loss: 0.655289\n",
      "Epoch: 19, Loss: 0.758775\n",
      "Epoch: 20, Loss: 1.334789\n",
      "Epoch: 21, Loss: 1.044897\n",
      "Epoch: 22, Loss: 0.761560\n",
      "Epoch: 23, Loss: 1.075333\n",
      "Epoch: 24, Loss: 1.151809\n",
      "Epoch: 25, Loss: 0.653913\n",
      "Epoch: 26, Loss: 0.933065\n",
      "Epoch: 27, Loss: 0.671137\n",
      "Epoch: 28, Loss: 0.766408\n",
      "Epoch: 29, Loss: 1.017472\n",
      "Epoch: 30, Loss: 0.625896\n",
      "Epoch: 31, Loss: 0.657589\n",
      "Epoch: 32, Loss: 0.503677\n",
      "Epoch: 33, Loss: 0.677622\n",
      "Epoch: 34, Loss: 1.286611\n",
      "Epoch: 35, Loss: 0.671177\n",
      "Epoch: 36, Loss: 1.236235\n",
      "Epoch: 37, Loss: 1.510834\n",
      "Epoch: 38, Loss: 0.707165\n",
      "Epoch: 39, Loss: 0.910691\n",
      "Epoch: 40, Loss: 0.347029\n",
      "Epoch: 41, Loss: 0.776057\n",
      "Epoch: 42, Loss: 0.564476\n",
      "Epoch: 43, Loss: 0.344131\n",
      "Epoch: 44, Loss: 0.666006\n",
      "Epoch: 45, Loss: 0.925424\n",
      "Epoch: 46, Loss: 0.848262\n",
      "Epoch: 47, Loss: 0.645637\n",
      "Epoch: 48, Loss: 0.521131\n",
      "Epoch: 49, Loss: 0.405103\n",
      "460.7569332122803\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "training(model, optimizer, loss_function, n_epochs, device, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5788d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational complexity:       0.0 GMac\n",
      "Number of parameters:           26.91 k \n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "\n",
    "macs, params = get_model_complexity_info(model, ( 3, 32,32), as_strings=True, print_per_layer_stat=False, verbose=False)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f2b66d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_53032/478742170.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mval_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_transformed_cifar10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_transformed_cifar10, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size=imgs.shape[0]\n",
    "        outputs = model(imgs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "#         print(predicted)\n",
    "#         print(\"\\n\")\n",
    "#         print(labels)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted==labels).sum())\n",
    "    print(\"Accuracy \", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2967e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2\n",
    "import torch.nn as nn\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight, nonlinearity='relu')\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62cc11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class ResNet10(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.ResNetBlocks = nn.Sequential(*(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(16 * 16 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.ResNetBlocks(out)\n",
    "        out = out.view(-1, 16 * 16 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f796e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0')\n",
    "train_loader = torch.utils.data.DataLoader(transformed_cifar10, batch_size=64, shuffle=True)\n",
    "\n",
    "model = ResNet10()\n",
    "model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 3e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ce4480f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.277361\n",
      "Epoch: 1, Loss: 1.145205\n",
      "Epoch: 2, Loss: 1.369397\n",
      "Epoch: 3, Loss: 1.273107\n",
      "Epoch: 4, Loss: 0.985361\n",
      "Epoch: 5, Loss: 0.914707\n",
      "Epoch: 6, Loss: 0.974068\n",
      "Epoch: 7, Loss: 1.109438\n",
      "Epoch: 8, Loss: 0.757056\n",
      "Epoch: 9, Loss: 0.472011\n",
      "Epoch: 10, Loss: 1.034962\n",
      "Epoch: 11, Loss: 1.147394\n",
      "Epoch: 12, Loss: 1.052102\n",
      "Epoch: 13, Loss: 0.755030\n",
      "Epoch: 14, Loss: 1.113185\n",
      "Epoch: 15, Loss: 0.841514\n",
      "Epoch: 16, Loss: 0.936391\n",
      "Epoch: 17, Loss: 0.979432\n",
      "Epoch: 18, Loss: 0.753448\n",
      "Epoch: 19, Loss: 1.169849\n",
      "Epoch: 20, Loss: 0.932154\n",
      "Epoch: 21, Loss: 0.801022\n",
      "Epoch: 22, Loss: 0.853775\n",
      "Epoch: 23, Loss: 1.280312\n",
      "Epoch: 24, Loss: 0.591497\n",
      "Epoch: 25, Loss: 0.702138\n",
      "Epoch: 26, Loss: 0.549943\n",
      "Epoch: 27, Loss: 0.433996\n",
      "Epoch: 28, Loss: 0.658836\n",
      "Epoch: 29, Loss: 0.595716\n",
      "Epoch: 30, Loss: 0.637904\n",
      "Epoch: 31, Loss: 1.116959\n",
      "Epoch: 32, Loss: 0.430917\n",
      "Epoch: 33, Loss: 0.588980\n",
      "Epoch: 34, Loss: 0.595428\n",
      "Epoch: 35, Loss: 1.095741\n",
      "Epoch: 36, Loss: 0.505264\n",
      "Epoch: 37, Loss: 0.889230\n",
      "Epoch: 38, Loss: 0.706902\n",
      "Epoch: 39, Loss: 0.769269\n",
      "Epoch: 40, Loss: 0.202074\n",
      "Epoch: 41, Loss: 0.546021\n",
      "Epoch: 42, Loss: 0.389091\n",
      "Epoch: 43, Loss: 0.507857\n",
      "Epoch: 44, Loss: 0.347831\n",
      "Epoch: 45, Loss: 0.517485\n",
      "Epoch: 46, Loss: 0.645606\n",
      "Epoch: 47, Loss: 1.009173\n",
      "Epoch: 48, Loss: 0.948069\n",
      "Epoch: 49, Loss: 0.732530\n",
      "545.6566236019135\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "training(model, optimizer, loss_function, n_epochs, device, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd4106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "\n",
    "macs, params = get_model_complexity_info(model, ( 3, 32,32), as_strings=True, print_per_layer_stat=False, verbose=False)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15df9199",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_transformed_cifar10' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19628/478742170.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mval_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_transformed_cifar10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_transformed_cifar10' is not defined"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_transformed_cifar10, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size=imgs.shape[0]\n",
    "        outputs = model(imgs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "#         print(predicted)\n",
    "#         print(\"\\n\")\n",
    "#         print(labels)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted==labels).sum())\n",
    "    print(\"Accuracy \", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2af2a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 2B\n",
    "\n",
    "import time\n",
    "def training(model, optimizer, loss_fn, n_epochs, device, train_loader, l2_lambda):\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            batch_size = imgs.shape[0]\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn((outputs), labels)\n",
    "            l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "            loss = loss + l2_lambda* l2_norm\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "    end = time.time()\n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3480722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.640708\n",
      "Epoch: 1, Loss: 1.354963\n",
      "Epoch: 2, Loss: 1.459355\n",
      "Epoch: 3, Loss: 1.055936\n",
      "Epoch: 4, Loss: 1.251605\n",
      "64.18126511573792\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "l2_lambda = .001\n",
    "training(model, optimizer, loss_function, n_epochs, device, train_loader, l2_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4896cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleLinear ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleLinear ptflops can affect your code!\n",
      "Computational complexity:       0.0 GMac\n",
      "Number of parameters:           26.91 k \n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "\n",
    "macs, params = get_model_complexity_info(model, ( 3, 32,32), as_strings=True, print_per_layer_stat=False, verbose=False)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e3d8010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.5984\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_transformed_cifar10, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size=imgs.shape[0]\n",
    "        outputs = model(imgs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "#         print(predicted)\n",
    "#         print(\"\\n\")\n",
    "#         print(labels)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted==labels).sum())\n",
    "    print(\"Accuracy \", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cd2cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class ResNet10(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv1_dropout = nn.Dropout2d(p=0.3)\n",
    "        self.ResNetBlocks = nn.Sequential(*(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(16 * 16 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        out = self.ResNetBlocks(out)\n",
    "        out = out.view(-1, 16 * 16 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "973b3352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0')\n",
    "train_loader = torch.utils.data.DataLoader(transformed_cifar10, batch_size=64, shuffle=True)\n",
    "\n",
    "model = ResNet10()\n",
    "model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 3e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75a32a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.181746\n",
      "Epoch: 1, Loss: 2.031161\n",
      "Epoch: 2, Loss: 1.419549\n",
      "Epoch: 3, Loss: 1.477833\n",
      "Epoch: 4, Loss: 1.336382\n",
      "60.43223571777344\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "l2_lambda = .001\n",
    "training(model, optimizer, loss_function, n_epochs, device, train_loader, l2_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df3a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "\n",
    "macs, params = get_model_complexity_info(model, ( 3, 32,32), as_strings=True, print_per_layer_stat=False, verbose=False)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96afbcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_transformed_cifar10, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size=imgs.shape[0]\n",
    "        outputs = model(imgs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "#         print(predicted)\n",
    "#         print(\"\\n\")\n",
    "#         print(labels)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted==labels).sum())\n",
    "    print(\"Accuracy \", correct/total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
